# CI Workflow Contract: End-to-End Tests
# GitHub Actions workflow specification for E2E test execution

workflow:
  name: "End-to-End Tests"
  file: ".github/workflows/test-e2e.yml"
  description: "Complete workflow testing from data discovery to NWB validation"

triggers:
  pull_request:
    branches: ["main"]
    types: [opened, synchronize, reopened, ready_for_review]
  push:
    branches: ["main"]
  schedule:
    - cron: "0 3 * * 0" # Weekly on Sunday at 3 AM UTC
  workflow_dispatch:
    inputs:
      dataset:
        description: "Dataset to test with"
        required: false
        default: "minimal_ephys"
        type: choice
        options:
          - minimal_ephys
          - minimal_ophys
          - minimal_behavior
          - all

jobs:
  e2e-tests:
    name: "E2E Tests"
    runs-on: "ubuntu-latest"

    timeout-minutes: 45

    services:
      # Full stack for E2E testing
      graphdb:
        image: "ontotext/graphdb:10.5.0"
        ports:
          - "7200:7200"
        options: >-
          --health-cmd "curl -f http://localhost:7200/rest/repositories || exit
          1" --health-interval 10s --health-timeout 5s --health-retries 5

      mcp-server:
        image: "agentic-neurodata-conversion:latest"
        ports:
          - "8000:8000"
        env:
          GRAPHDB_URL: "http://graphdb:7200"
          LOG_LEVEL: "INFO"
        options: >-
          --health-cmd "curl -f http://localhost:8000/health || exit 1"
          --health-interval 10s --health-timeout 5s --health-retries 10

    steps:
      - name: "Checkout code"
        uses: "actions/checkout@v4"
        with:
          lfs: true
          fetch-depth: 0 # Full history for provenance testing

      - name: "Setup Python"
        uses: "actions/setup-python@v5"
        with:
          python-version: "3.12"

      - name: "Install system dependencies"
        run: |
          sudo apt-get update
          sudo apt-get install -y git-annex  # For DataLad

      - name: "Install pixi"
        uses: "prefix-dev/setup-pixi@v0.5.0"
        with:
          cache: true

      - name: "Install dependencies"
        run: "pixi install -e test"

      - name: "Setup E2E environment"
        run: |
          pixi run setup-e2e-env
          pixi run wait-for-services
          pixi run verify-service-health

      - name: "Download test datasets"
        run: |
          pixi run download-test-datasets
          pixi run verify-datasets

      - name: "Run E2E tests"
        run: "pixi run test-e2e"
        env:
          PYTEST_MARKERS: "e2e"
          MCP_SERVER_URL: "http://localhost:8000"
          GRAPHDB_URL: "http://localhost:7200"
          TEST_DATASET: "${{ inputs.dataset || 'minimal_ephys' }}"
          E2E_TIMEOUT: "1800" # 30 minutes per test

      - name: "Validate NWB outputs"
        if: always()
        run: |
          pixi run validate-nwb-outputs
          pixi run generate-validation-report

      - name: "Upload test results"
        if: always()
        uses: "actions/upload-artifact@v4"
        with:
          name: "e2e-test-results"
          path: |
            tests/results/
            tests/logs/
            tests/reports/

      - name: "Upload NWB outputs"
        if: always()
        uses: "actions/upload-artifact@v4"
        with:
          name: "e2e-nwb-outputs"
          path: "tests/outputs/*.nwb"
          retention-days: 7

      - name: "Upload validation reports"
        if: always()
        uses: "actions/upload-artifact@v4"
        with:
          name: "e2e-validation-reports"
          path: "tests/reports/"
          retention-days: 30

      - name: "Performance summary"
        if: always()
        run: "pixi run generate-performance-summary"

      - name: "Cleanup E2E environment"
        if: always()
        run: "pixi run cleanup-e2e-env"

quality_gates:
  - name: "All E2E tests must pass"
    condition: "success()"
    blocking: true

  - name: "NWB validation must pass"
    condition: "validate-nwb-outputs == success"
    blocking: true

  - name: "Services must be healthy"
    condition: "verify-service-health == success"
    blocking: true

  - name: "Performance within thresholds"
    condition: "performance-summary == acceptable"
    blocking: false

performance_targets:
  max_duration_minutes: 30
  max_test_duration_seconds: 1800
  parallel_execution: false
  cache_dependencies: true

validation_requirements:
  nwb_schema_compliance: ">99%"
  nwb_best_practices: "warnings allowed"
  metadata_completeness: "100%"
  provenance_tracking: "complete"

outputs:
  artifacts:
    - name: "Test results"
      path: "tests/results/"
      retention_days: 30

    - name: "Test logs"
      path: "tests/logs/"
      retention_days: 14

    - name: "NWB outputs"
      path: "tests/outputs/*.nwb"
      retention_days: 7
      size_limit_mb: 500

    - name: "Validation reports"
      path: "tests/reports/"
      retention_days: 30

    - name: "Performance metrics"
      path: "tests/performance/"
      retention_days: 90

notifications:
  on_failure:
    - github_check: "E2E Tests Failed"
    - pr_comment: true
    - include_logs: true
    - include_validation_report: true

  on_success:
    - github_check: "E2E Tests Passed"
    - update_metrics_dashboard: true

environment_variables:
  PYTEST_MARKERS: "e2e"
  MCP_SERVER_URL: "http://localhost:8000"
  GRAPHDB_URL: "http://localhost:7200"
  TEST_DATASETS_DIR: "tests/fixtures/datasets"
  E2E_TIMEOUT: "1800"
  TEST_ENV: "ci"
  LOG_LEVEL: "INFO"
  VALIDATION_LEVEL: "full"

resource_requirements:
  memory_mb: 8192
  disk_space_mb: 20480 # 20GB for datasets and outputs
  cpu_cores: 4
